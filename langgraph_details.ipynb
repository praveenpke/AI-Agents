{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph Detailed Tutorial\n",
    "\n",
    "> **Build a Customer Support Agent from scratch — step by step.**\n",
    ">\n",
    "> Each step solves a problem from the previous step. Covers **every core LangGraph concept** — from simple graphs to production deployment.\n",
    "\n",
    "| Pinned to | Version |\n",
    "|---|---|\n",
    "| langgraph | 0.3.x |\n",
    "| langchain-openai | 0.3.x |\n",
    "| Python | 3.11+ |\n",
    "| Last verified | 2026-02-06 |\n",
    "\n",
    "If code breaks, check the [LangGraph changelog](https://github.com/langchain-ai/langgraph/releases)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Installation\n",
    "\n",
    "Run this cell first to install all required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install langgraph langchain-openai langchain-core pydantic IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Set your OpenAI API key (or load from .env)\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n",
    "\n",
    "assert os.environ.get(\"OPENAI_API_KEY\"), \"Please set OPENAI_API_KEY\"\n",
    "print(\"API key loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: The Simplest Graph\n",
    "\n",
    "**Goal:** Understand the building blocks — **State**, **Nodes**, **Edges**.\n",
    "\n",
    "Every LangGraph app is a **state machine**: data flows through nodes, and edges decide what happens next.\n",
    "\n",
    "### Architecture\n",
    "\n",
    "```mermaid\n",
    "%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#E8F5E9', 'primaryTextColor': '#1B5E20', 'primaryBorderColor': '#4CAF50', 'lineColor': '#4CAF50', 'secondaryColor': '#FFF3E0', 'tertiaryColor': '#E3F2FD'}}}%%\n",
    "graph LR\n",
    "    START([\"__start__\"]) --> greet[\"greet\"]\n",
    "    greet -->|\"'order' in message\"| order_handler[\"order_handler\"]\n",
    "    greet -->|\"otherwise\"| general_handler[\"general_handler\"]\n",
    "    order_handler --> END([\"__end__\"])\n",
    "    general_handler --> END\n",
    "```\n",
    "\n",
    "**Key concepts:**\n",
    "- **State** = a TypedDict that carries data between nodes\n",
    "- **Node** = a Python function that receives state and returns updates\n",
    "- **Edge** = connects nodes (normal = always, conditional = based on state)\n",
    "- **START/END** = special entry and exit points\n",
    "- By default, node return values **overwrite** state keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I need help with my order Welcome to Acme Support! [Routed to Orders]\n"
     ]
    }
   ],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# 1. STATE: The data that flows through your graph\n",
    "class State(TypedDict):\n",
    "    message: str\n",
    "\n",
    "# 2. NODES: Functions that read state and return updates\n",
    "def greet(state: State):\n",
    "    return {\"message\": state[\"message\"] + \" Welcome to Acme Support!\"}\n",
    "\n",
    "def classify(state: State) -> str:\n",
    "    # This will become smarter later\n",
    "    if \"order\" in state[\"message\"].lower():\n",
    "        return \"order_handler\"\n",
    "    return \"general_handler\"\n",
    "\n",
    "def order_handler(state: State):\n",
    "    return {\"message\": state[\"message\"] + \" [Routed to Orders]\"}\n",
    "\n",
    "def general_handler(state: State):\n",
    "    return {\"message\": state[\"message\"] + \" [Routed to General]\"}\n",
    "\n",
    "# 3. BUILD THE GRAPH\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"greet\", greet)\n",
    "builder.add_node(\"order_handler\", order_handler)\n",
    "builder.add_node(\"general_handler\", general_handler)\n",
    "\n",
    "# 4. EDGES: Connect the nodes\n",
    "builder.add_edge(START, \"greet\")                    # Always start here\n",
    "builder.add_conditional_edges(\"greet\", classify)     # Route based on state\n",
    "builder.add_edge(\"order_handler\", END)\n",
    "builder.add_edge(\"general_handler\", END)\n",
    "\n",
    "# 5. COMPILE & RUN\n",
    "graph = builder.compile()\n",
    "result = graph.invoke({\"message\": \"I need help with my order\"})\n",
    "print(result[\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAegAAAEICAIAAAAbdvDZAAAQAElEQVR4nOzdCXzT5P8H8Cft1t0bDLYxjnGNU0BADuH/E8QhiMolKvcxQECQQ0EQwYNLBRHxQkTEgZwCyi2iIKAoiggCguBggA7mlI2N3WuT/7fNlqVt2q3Yrcn2eYt7pbmaJnm+efLNk8RLEAQGAADa4cUAAEBTELgBADQGgRsAQGMQuAEANAaBGwBAYxC4AQA0pvjAvf/TpH/+zM3NKmg1yHFMakDIcZzUmlCn1/E8zwRn4+i9ON5Y1PxQPpr0UadjNBv7oYxjBTPX0QAaJNiOII2oYwLPHNHR5Iy+QnlyGipYZm4/od7A+fiyBq0CW3aqwlTPZDLtWXU9I82Ul118c08vL53RaLXKaCULvO2EtPlMRque8o0rkbagVU89x5vsx+R4+2+hMXmFTWDewUwK25XGN5kUfqP9jyqYD8d4B6vE0ayYgxUi8fHT+QWxmAFhgSF+TPXOfH/z3I9p+blCfr79wIJiZlc2zRtaLFlWpbugUMrG1FtKn3zawvJonom56Np+pY7jeEGQ7wxit7R32exm1rtN4QLbbSB5HLDZ0wrmb/dzbH6P/Tyl+ShMa/WLCvYx+Qg2P4o5KD4+flx4lM99j1djTnFO2nFnpOateeWqgQJWoJcpr3ACq6Bs3pqFy2r+ULhEtHk4hXH0jDdZfbk0moVgXnPSurMZahkoLoC49R2sNcuq4QtGtvQQLNOwwuWkaS2/2vbbC2fOlDeGXs9Mgikngzf4ciPn1Gcq9v2uv09+c8snkPP188rPtR8uyNaOmX3A4ixrx2Yy+4hs3hTWq5c5iIzmtWdixc6QWYqEef9mtptGr+NMSqFTcSbMwaGC2f/4Ekzi5FtEXgaWm52fm8Uatw26r38EU7GPX76Ymy34Beo4nY432q0JqZRZR2SxFIs9rcud7eo0ryiTVT9pfKnk2iiosVnCt7yPFDpsDw/yz7Kw4OSOFJsQWTh/yyRKcaBwPNkgMThJv8Vp4JZWinxJC0cuWmP2hz1mrnAI2Vm8ycgPmREVGGpgjn6Ro8B9IzF745uJHXpWbdCyEgOZ7R/E52dysWqN3Ye2Jp85mj5sdjSDMrd2QXzDVgExAyOZKq1ecInCR98J9Rio2+/HU3/ac2PgszVCI5TP4XSOpvz0rcSOPcMQte31HhvtE6BbPf8iU58LJ9POImp7zpBZ0ed/yTx5+AZTn/WLriBqa0Xjuyq37xG6cXGioxGUAzfltb28ddEtQxgo6R5bIyNVYOrz4+6U0EgfBp5TLcr3xDfpTH1uJud3flylpwJgr1GbUC9v7uDWvxWHKgfuf67m+gY4rIyDwWCgK3UnDqUwlcm+ZQqrhcDtSRHR/rlZPFOZ87+kUVo2NEwD105B4hugT76SqzhIuVUJXb4QeEeXcMDMmM+y01VXPvPyqHjiiOtJPj5exlzVnY3l53JS+wLQCpOR5WQo70toxw0AoDEI3AAAGqMcuDkOeZJicKpdS9h2HlXQ8BjgPzPfLegg8ancW8DrFYojMKbSlYRNB4pwONEa812aJuVBSJUAuFPBzXEqhAN6OeIgVWK5MRw0h9IknB6tSsAOhxp3ueIgVcIjV1IMdea4zU/IMqmukWKFotKLHwJq3Npj3pE4V5oD4uJksdSZ46YTJU6HbedhgvpiJIcatwZZIozyZsPFyXLF/MxDHpsObAmocZcvDmrcqqw1qIql1RfqMGBLvRcnQWt0Oubo/Fk5cIuPnGXgmKDKFWTOieHapEepsx23JVvKQFsEx9Vn5cBtfqI8g2KoM58koICCHUHAKbT2ONloytUz3iQIiNwaZD6UlFWOe+lbr8WOepy5z2P9e6z86D1WamhpaZmpY+tnG7t2a89KB1IlperlOTOmPTve+Ti7dn/eJaaN0WhkpeObg1/R/G/eTC3h8pQGlZ5Xz5n73J4vtjPX9e13/7XriQwA5HAaVr6oNHCfP3+WuS4p6bp4GAQAKzgJ0CAnjTg9fMv70R+PbNq05vfzv4WGVm3W7M4xoydWqVKVTkNo0OuL572//M2d2w9mZGRs3rL2p2M/XL58sUpo1Y4dO4+MfdLX15fGeenl6Xq9PiIicuOmNSOGj41b/QH1HDyk9//9X+f5c99gpYnj1Nio5DbaumRlZS1Z+srJkz/fupVep3a9Hj169+n9GLPkE9Zv+PjpKTNpJffp8/jECdNozAWvzj5x4ljdutG9ez4qn0lKyo1l7y8589uvOTk5bdt2GDZkdK1atan/pUvxo54Y8OqCpYuXzK9UqfLKFRucL4yXl/dnn29a/sFSg8HQrFnLmc/NDQk2v4bphx++PfDNl6dOn0hPT2vSuNnQoaNbtTTvJAkJF0eO7r/svdXr13/83ZGDYWHhXe7tNuaJibRX0NDLly+9tvClK1cTWrZsQ4uk+I10Qv3RqmVHf/wuOTmJvrFv78fvvvt/4qDefWNoqsPfHTh16sTunYf9/f1ZCZSbh0zxPP/W2wtprRq8DTExDzS7486Zs6Zs3fxlaGgVGrr3y507dm5NSIinneG+Lt36PTJQvPmDzpWpo2tMj9cWvZydndW0afNxYyY3adKMlXhVb992QMfpHBX5krtx4995C57/7bdTNWtGDeg/7KEH+4j9aQc7evTbc+fOGHx87mzRetSoCTWq16T+n2/79JO1K5cuWfHSnOm059SrF/3Yo4Mf6N5TnGr5B2/t+2q3v58/rYqaNWsrfqO7SoHEySVl5Ro3pyuLW3Au/PH7zOcnt2rVNm7VlkkTp1+8eGHhopep/949R+jvs9NeoKjNzCuaIkhc/8eHvrJg6dixkw8e+mr1mhXiHLy9vS8lxNO/BfOW9O71KK0a6rlu7fbSjtpMvG6gvlrMbbQqee75Sdeu/TVv7hufbtzTqVMMldVzv//GLG/5ycrK3LFjC0VPKmPUZ/Eb8/766+ri19+fN2dxwuWLVALFOZhMpqenjj356/Gnpzy/auWmypVCx08YnnjtL2bZQPR3zdqVtPmmPjO72IU5dPjrzMyMha+98+y0F8+cOfnxx+9TTyoGdMDIzc19bsYc2geiourMmv00FRJp/m8smU/Fad/eH2bNnP/p5rWUgqSe+fn5M2ZODAuLoL1r7BOT6NBOJdn+G99+Z9GWrev79um/ft3Ozp1iqNAeOrxfHEQz37Xn8+joRq8ves/HR9vvFbqNG3A2b1m3c9dnE596dvnytX5+/hRzmbmBmnn3+nr/3oWL5jRs0Hj92h2jR02gFfjusoIS5+Xl9dvZU199vWf5+598sfs7H4PPqwtfEgeVcFVTcHRS5EuIFuPtdxcNHTJ6yRvLGze+g65t/P13EvU/ffrkO+++fscdd86du5h2p9TUlAWvzJaWISPjFi3ks1NfOPD1sc6dui56fa441fYdW7bv2Dx50oxly9ZERtZY88mH9t/oxlIgMT9kysG1Rkc17rJo7Xbm9Ek6ig4ZPJL2hoiIao0bNaUQbD/a448Noc1cu3bdgqnO/PrTse/HjpnELEekpKRry5d94urRuLzizbe8u3A8oTMe2pVpP6tb1/zS+sGDYn/86QgVktdeeYvWLUXMAQOGt27Vlgb9++8/FBBnTH+pqaX2ROv/+x8OizOhOVy9evmNxe+LYz45bsqR7w9t3bqeDsbi8b9tm7up8lKS5fH3Dxg6ZJTYTTOhKjZ10MZduWKjn59fSIj51dVU46aCdPrMSdorxDGpjN3buSt13Hln6+qRNS5cONc15oHD3x5ITv77rTdX0q5Fg2hh6OKnzdfRweDLfbsGDRzRq2c/+vhgj960d1GxFOdMCx8cHEKnGswV6rw4KUh/SozWTKd77hNXLO0YVOikQXv2bGvRotWUyc9Rd+XKobHDxy1aPHfIoJHUTX2ys7LouCueoMTc9wBVvelcjc6BSr6qnRT5EqLafa+ej7Zv15G6w8Orff31F+d+P0N7Ap0BfPzRp1QHp8huHi0///nZT6elp4kndnSwHz5sDI1D3d27Pfxx3PL4+PM0FR1IaB8TF5Xq4FRbpxqMzTe6sRSUhIN23HxZVCebNW9JoYHOv9rc1b5Dh041a9QSz39t0PHq2M8/0Dlv/MUL4pVicf8Q1Y6qi6h92+hUl9aeGLVFDRs02X9gr/SxcaM7xI7rlku+tWsXvSO8UaOmf/zxO3VQDKVtJO6vzFIIW95516+nfpHPk5VM82Ytpe6Q4Ep5uQUv3KO6/8qP3qXqjFRrll/MaNiwaP6BgUFUb6KOxMQ/6adVq1bwelxKwYWHR9h8HYX4vLy8tm06SH1oyb/Yu0MqyY0aNmUuUmmqxHznpAuLRXkSShf0eKCX1KfTPTGUxxAHUTZg2NAnpEF00kw96SgrhrZaUXWktBJtDvpLWThKj5R8VTsv8iVEaRCxo1JIZfqbm5NDf+n4QeeX7y17g+J4ZmamOMLN1BRxGQhVz8WOoKBg+kv7kiAItC/JV4V8f5O4sRSUhOMcd+lHbjrVeu3Vtw8f3r/iw3eWvf/mXa3bUZ6aMt02o9FQOsLTGRNtdTr6rfzoPXmDE4OHzmHNTwXR/r0uFAd9fa1eIEtFjlKT0kdKmIgdaek3zUP9ivK8foUT0s5NVRXxyoSEcnlFMynxNhLrQSIpW0enq5OfHt26VbsXZr1CtSHqf3/3u+VTiefvNigb7udnlZX28bE9wIshfuLkUTb9U1NuiCVZ+vklp9LmgC6mSqhGRQGLToCkPuLpDjO/1zSPNjdlTsTkiYTSDmKH4uZwaVU7L/IlJO1L8rTvkSOHZr84lU4gxo6ZXL9+g5+P/zh9xlPyqexzxBTfKQ0i35dsioz0A91VCiQ6ncMY4zhwl8mlNzqXoX+xI8YdP/7j1s82PD9rymdbv5KPQHvPzl1bH+036OGH+op9xD1ABWj9qK6tu3mbufKQqYCAgJycbHmfzKzMqlXC7Mek+i/9zcnNkfpQLVjsoMos5TEWzH9TPr5ep2duQilOChaUkaRvYdZ1bSfo1Ft+BGKyBZZUqWr+pVOfmVWjRi15fzq5ZrdNnffUuvisEjGMUiSS+qSm3hA76DyGju7d7n+oU2GqSlQ9sqaTGZZ8VZdqkadMevPmLSkvX/I5UxmhenqubM+32a9EpVEKzM+McvDSdkdPB2Rl4OTJ47l5uRS4q1YN69794WrVqk95ZkzS39fDqoZL49Cuk52dXbWwDxVgKbXqWYJqXzXjymLR+SnVrf6IP98gupHYh/J3dWSZEwltHWbJNjaynCfSdqHailihqF+/IW0jKoHi1Xly7XqieH7qFlR3pvNWMWoz8wXM/SWZqlpEJP00uqBfr140fYyPv0BpeptxataIEq86Sjk6qjZaapolakCirFw8wYaqq5RZunz5otSHMrZSN23xWxm3pJVGOwNl0uwzUXIlX9WlWuRpX6IdQ/r47bcHip2E6uAREZG//XaKPVbQR7osL1capcBJUda5OoEbUabs5TnT6co11aHOnjtDVwAo8ue3gwAAEABJREFUgtNqpQ0cFhb+889HT5z8mU67oqLqUC6Mrs+mpd2kayCUBqWUmZSfkqPkGv09ePArmhurkAQX63vt2nWsXr3mkiULfj9/NiXlBp38UuDu/9hQ+zFpi1AWKy5u+Z9/XqFrevMXzJJOKinHRfNZvHge5TRoG23bvnnck0P37t3B3KRevQaU0tmxcyulO3/86ftffvmJTtspZ+p8qo4dO1O1cfGS+RS+KWTPnT8zuDCPKaGoQdk5ukRGV5YoQNAhYdr08eLdlf+BWm8ud/GA0rFDp31f7T7281EKr5u3rKNCJw16YtRTR44cpPQFpbZp1c2dN/OZaeNoBTqZW8lXNW21khd5V0XXb3jMElhoX6IfJfakyqLzqbrcez9d6xZbK23YuPrs2dP245R2KbDhMEtbBvseXTt+6MG+7763uG+/+59+Zgwl1N5cskLMTA0eNPKXE8deeHFqdk42ZTZ9fXxHxD46ZFgfWjujRz9FH/v263o96ZrNDOlYR9d86Vrwhx++wyoozqWjLq3t+XPfoIg2fsLwQUN6Hf/lp3lzF9O5pOLIM5+b26RJszHjBj/UsxNVgR/s0Vt6WsurC5Z27tyVgmOfR7rSAbhr1x6PPDKAuUnMfd2HDhlFZZ5S2+Jl+vu7Prh+Q9ySN19xMlVgYOArC5aajMaHe3UeMfJROvWWWinIDeg/7NlpL67fGNez971vvb2QzvenTnWhwZaWuFikhw8b07x5K0oBDx3W98qVBFqBzNLQnv7SHrJi+Tq6Vkkll+JvZmbG/HlLim0xWfJVXfIi76qRI8fTKf7sF57p9kAHirCUf2vcqOlzMyd9vX+vk6mGDB710IN93nn3dUph/3D02/FPPsOUHlVUqqXABqf4pKTV8y5TbqXflNoMHFg952LrLiEde1ZlavLuMxebdQi5q5u6lqpCOX88/eiO5KeWRjM1OXM0/eCm5OEvu7BUdKZCpzVRlrNYsnHTmnXrVu3ccZBBWdn61lW9Thg6WyEO4xmgt8ly56Tqspl0PZ/T47EUHqXOi5Ouo0hNZ1dbP9tIJ/4Hvtn36ea1vXo9yqAMcZzDsyT3vCy4Z697FfubTCadzuFdmGs/2Sa1MXIvyqM9P2uK4iDKr3l7eysuUu069d59exUrGcudk6rLZfK8azfglCUnG4WV5s5QxtR5bfI2FmrE8DFpaan79u36cOU7YWERffv0HzwolqkDJco2bIhTHORSKVY5nhccBU/3PKtkxYr1zHWlV1DNOTgHi0T5uICAQMVBXnoPP7nFPdTaqsHJRmGluTOUMRU/1tXlHWPypBlMlXr27NelSzfFQeWkFBfHwY90sdVnpKWtmKqU9iK52mK67Kj4daEq3E/cTp13Tt7GLe9qFhQYFGS5J7PCwsuCb5N5/ajvtbwcU2PmvULBixTAXZw8HdDBq8t0HN4VrkUCggYowm6hRa6+c5KS4oKAipszdCzUqbNui5Mlz1JtqxLsF1rDOX7Lu3KqRKfDCXcxKDzy6guR5vZDHAqoJ5kLjjofMgVaY65AO3geks7hBCj+GkTnSRza5nuUSsuNwCF2lydOatzYztqDbQbKOLU+QQVui5McNwPNEZgabwsCVcBRvRypEI3VAQDKEwRugAoADUXLF+XA7e3L8XkMnPDyZj5+qrsM6GXg3PfmGbgdRqPJ20d9Tx/T83ov5Eo0xsubMxiUt5py6AkN987JMTFwzGQSolv5MZXx9eP+vZ7LwHOSr+R4eeY1qM40bVeJrluZTCjUWpKTZawU7q04SDlwPzC8el42n56CWreyAxv/9AvgQqqoLnA3uCvwnz+zGXhOUkJm3Tv+w5vPSk1giO7rtdcZaMSNpOz8HKH7sEjFoQ5P9u+KqbRj2VUGdk4cTkqMzx05pz5Tn/97OKxyNcOGhfEMPGHj4vigyl739Y9k6jP8xXr/Xsv5djcKtTbs/jCx3QMOH5nJOWk9lnA244tVSUGV9SFVDUwxdWpuHCpLwQiWA4Fge88vJ71Oiyu4IdjyrdbjiNdOCkegvxxnd9s9TSQ+KFzp5jTLl3CyedkQLM9sKWzOKsgXr2AliC3XBUFpyc1t24Wc7Pz0f4x0LjJukbreb2Jj16rExD9ygit7BVc1mEzOMptWq72oZ9HWsVmXnI4T5E+xKdzUnN0b02hD8YLCphDHtB3fcneIIDCFG8Y5y7i2M+fsH4du2XxW+4zjHUH2RdJPkEbmCkcr3DfkS6s4T72eT0vJu3XDFF7L0Hd8LaZiHzwX72XQVarq7RtI+4btT7EtdGJJVPrJBZvRZjuKm9bptLZ9ZBvcat8oHM92D+QsO6dUKhnjrYYWBTSrrSbbb+XjiHup7W+32gEUHiEhLZJCjCoMiVzhOipYT1KQKWxRb+4w/2c3K4G/+U9uRqrp4VHVopooP4CaOQ/cJC8jb9vKpIzU/JwsxeFWxaywyy4oF/54sUNnWUbFzSnfcjarjKbQUQnSm1c0zYESduJfm2+R1pftUMtA8ekiNmVe2vaWoVZxSR7C9HShwEcIr+Hz0OiaTPV+PZRy+sjN3GwuN8fBPbMFRzLFdVVUVGy2gpdOZ+R5VgLm55QpPahM2kzyYZZAbNkqdnFbPFLb7C56y8xt5m4/ZuF3CczuOQDSRpcVwqK9VHq4j1iw5etHVqiL+PjqDH6sUZvAdt3CmOrtibuWfDU7L4cz5ttuIHkgY07Lo/KewzNBJ81KHGQbqOXBzmZlcgV1P8tsCudss0iWZ3cUfalOz/Gyw484rXxuIr2ek45StPOYCuco30ttwpTVGmBW1UVZiBdjL5PFnoIaiOUORnMwEdeJ9KWWI4j4u8XX1QiCrIpAHb7+XFBl797jIwwGA3OM08r9GtOnT+/evXtMTAwDAKjYNNOO22g0ii+ABwCo4BC4AQA0BoEbAEBjNBMK8/Pzvb29GQBAhYcaNwCAxiBwAwBoDAI3AIDGIMcNAKAxqHEDAGgMAjcAgMYgcAMAaAwCNwCAxuDiJACAxqDGDQCgMQjcAAAao5lQaDKZELgBAJhWAjdVt/V6PQMAAA0FblS3AQBECNwAABqDwA0AoDEI3AAAGqONaIi7bwAAJKhxAwBojDaioSAIkZGRDAAAtBK49Xp9YmIiAwAArQRuypNQtoQBAAACNwCA5iBwAwBoDAI3AIDGIHADAGgMAjcAgMbomBbo9Xqe5wVBYAAAFZ42AjdDpRsAoBACNwCAxmjmASAI3AAAIgRuAACNQeAGANAYBG4AAI1B4AYA0BgEbgAAjUHgBgDQGE7ltyO2atWKsxCXkzp4nu/SpcuSJUsYAECFpPYbcNq3by8Gbp0FdYSHh8fGxjIAgIpK7YF78ODBVapUkfdp0qRJ8+bNGQBARaX2wH3PPfc0bdpU+hgcHDxw4EAGAFCBaeBZJcOHDw8NDRW7o6OjKXnCAAAqMA0Ebro+2axZM+oICAhAdRsAwM2tSlKuZ/z6XUZuJs/LDgkcZ/5HveR96Gv1Os7EC/I+zHIk4a1H4wSWlp726+lTPj4+7dq2KxjTPICzXwD5PKWZ0DxNSr9Sr2cBIfr/9QpjAADa4c7AvWZ+wq2bJoOBM+ULvFAUVc0BlqKtPHDrzB91eo432QZucVDhaBzNiKal2M0LAmeJ1GJP6kPxWFr2orivZ7zJaqlofPor8Ao/09tAhxPBmM+iGvr2HFuTAQBogdsCd9zcBL036zO+LtOatJTsncsTm3cM+V9vVL0BQAPcE7jj5lzyDdQ9NLoO06xNiy9GNfLvNiSSAQComxsuTv55IT0rg9d01CaN2gdfOp3JAABUzw2B+8yRDB9fzbwCzZGW94RRcjwtNZsBAKibGwJuTo5gcz1Qo3iepSczAACVc8fTAXmufARuebsXAADV0sxjXcuAub05AwBQOzcEbnO803yKu5AOoRsA1M4dNe5yFOtU/nRyAADmlsBNqeHykR0WytUxCADKLeS4i3CW2A0AoHJuynGXj5qq5YFWAAAq544ad7lJDHNMQK4EAFTPLamS8hPtuHJy7gAA5Zk7Lk6ycpIbpkusHFqVAIDq4eJkEU7HcO8kAKgfArcVXJwEAPVzS6sSjis3NxzizkkAUD033KsuEF5dNdWEhIsDBj3MXIc7JwFA/cpnquT8hbPMdZY7J1HjBgC1c0eqhLncIJDn+bfeXvjdkYMGb0NMzAPN7rhz5qwpWzd/GRpapXffmGFDRh/+7sCpUye2bzsQHBS898udO3ZuTUiIr1s3+r4u3fo9MlBqtKc46OO45Ws+WUlDu8S02bn9YGBgYAmXynLnJGrcAKB27kiVMJebA27esm7nrs8mPvXs8uVr/fz8P1q1zLwoOvPCeHt779rzeXR0o9cXvefv5//1/r0LF81p2KDx+rU7Ro+asGXr+neXvSHOxNGg2BHjBvQfFhFR7Zv9P5c8aou/pNw85RAAyjE3RCqOE1x9rOuX+3Z1uue+ezt3DQkOGTwo1j8gQDY3Ljg4ZOKEaW3uau/l5bVnz7YWLVpNmfxc5cqhrVu1jR0+btu2T1NTU2hMJ4Nu95cwvvw8oBYAyi23XJzkXHo6oMlkunz50h13tJD6dLonRj5Co4ZNxQ7KqJz57de2bTpIg1q1aks9T50+4WQQ+w84Hi25AUDtPHBxMis7SxAEf/+iWnZISCX5CAaDQezIy8vLz8+nRIqYS5FQtdrJIHa7BKG8PC0LAMo1DwRuP18/+kthV+qTmnpDcUxfX19/f/9u9z/UqZNVlbx6ZE0ng9jtoqiN1oAAoH5uCtyuVFQpcx0eHnH58kWpz5HvDzkauX79hrcybrVq2Ub8SOH++vVEmtz5oNuFhwMCgAa45eIk5+pD9Tp26LTvq93Hfj5KOZPNW9bdupXuaMwnRj115MjBPV9sp/z16dMn586b+cy0cZQncT6oZs2oGzf+/e67g0ajkbmAQ+QGAPXzzJ2Tw4eNad681fQZTw0d1vfKlYRH+w1i5pq4t/2YzZu3XLF83alTJ/r2u3/a9PGZmRnz5y3x8fFxPuju9v9r3qzlCy9Ny87JZq4QELkBQPW4/36T9+fvXUu+mjPo+XolnyQnJyc5OSkqqo74ceOmNevWrdq54yDzqNUvxfcdX6NGQz8GAKBinmm2TJF6zLjBWz/bmJZ288A3+z7dvLZXr0eZx+HiJABogXtueXe1Fd2I4WPS0lL37dv14cp3wsIi+vbpP3hQLFMBAe0BAUD13PIGnNt5ivXkSTOY+iBsA4D6uaU5YDl6NBNyJQCgengDDgCAxiBwFxF4JuAZUwCgegjcRTgd4/CMKQBQPbe8c5KVn4eholUJAKieGwI3zwsmXJwEACgr7nnLu65chDvzg8V1SHIDgNohx13E/CofvEgBAFQPgRsAQGMQuAEANMYNgdvLmxl8y0NqWKen/3FxEgDUzg0BN7AKl5/n0vsK1CgzI4/y2zUb+DMAAHVzQ+Du0i/SZGRJf2YyLfth214bylgAAAjCSURBVD8BIWhSAgAa4J5Q1fCuwK9WX2ealZyUcT0he9js2gwAQPXc8AYc0ZWzt3at+rtalCGqSZB/gF7g9NbfIz5DUOBkT04VCh+jKu8vyJ6tanmxAVeCnubJBdkXFfwwzvq7BNvHtgqckJacm/DbrVspxvGvRzMAAC1wW+AmZ4+n/LQrNSdLMOY5GENw8MRrR/0Lo7B1z5K9qMZ+NLu56fSc3osFV9EPfLYOAwDQCHcG7lI1ffr07t27x8TEMACAik0z7biNRqOXF1qdAwAgcAMAaA0CNwCAxiBwAwBoDAI3AIDGIHADAGgMAjcAgMZoJhTm5+d7e3szAIAKDzVuAACNQeAGANAYBG4AAI1B4AYA0BhcnAQA0BjUuAEANAaBGwBAYxC4AQA0RhuhkKK2Xq/nOI4BAFR4mgncqG4DAIgQuAEANAaBGwBAYxC4AQA0BoEbAEBjELgBADRGG9GQ5/mGDRsyAADQSuDW6XQXLlxgAACglcBNeRLKljAAAEDgBgDQHARuAACNQeAGANAYBG4AAI1B4AYA0BjNBG6TycQAAIAxHdMIvV6PSjcAANNQ4Ea2BABApJkHgCBwAwCIELgBADQGgRsAQGMQuAEANAaBGwBAYxC4AQA0BoEbAEBjOEEQmIq1bt1a7OA4jv6KS9uiRYu4uDgGAFAhqf0GnAYNGjDLG3A4C+oICAgYOXIkAwCoqNQeuAcOHBgUFCTvU79+/U6dOjEAgIpK7YG7T58+tWrVkj76+PgMGjSIAQBUYBp4VklsbCylR8RuCuLdunVjAAAVmAYCd0xMTN26dZmlYQllThgAQMXmQnPAxPjM3AxB0Jlbd3BMMLdIMXcwnhN0Aie1TaE+lm5xoGUExnFMKBwqCJb+9gomkD5y5v/E7ke6T8hPXe8fENisbteLpzLtp7X5Utk8aRZ2X8dZeistAscKfkjhDMVuY5WahpBQPwYAoAIlag64e1XilXPZFMl4XhbP7NmGTee9nQ0zR3reahAtp9giUHFaznJAUJiZs+9W+l6l38fpzf29DazLgLDoFiEMAMCjig/ch7b8fe74rXbdqjZoXYlVYN/vSfrjWMaAaTWrVvdlAACeU0zg/uy9qynX8/o/G83A4pN58d2Hh9dvHswAADykmIuTSQl53UbUYFCoZgP/Q1v+ZQAAnuMscH+/K1nvxSqH4aJckRb3Vs7O4BkAgOc4a1WSdUtgnCuX9iqAKtX81P1wFwAo/5wFbpORM+YjStnBKgEAj9LMY10BAECEwA0AoDHOArdex7y8NHBPPABAheI0x80zoxEtKAAA1AWpEgAAjXEWuDkOrQEBAFTHaY1bcPQUPQAA8JhiUyVotAwAoC7OArfAOIRtBVgpAOBRyHG7DusEADzKaY1bYHguBwCA2ji7v0anYzrtVLljRz2+9K3XGABAeVdcjZsBAIC6FJsqQegGAFAXVdw5aTQaP1q17OiP3yUnJzVr1rJv78fvvvt/4qA+j3SNHTEuLe3m6jUr/Pz82rbp8NSEaVWqVKVBly9fem3hS1euJrRs2WbYkNEMAKBicJbjLrNWJW+/s2jL1vV9+/Rfv25n504xL82ZfujwfnGQt7f3pk1rdDrdts/3r/546+kzJ+NWf0D98/PzZ8ycGBYWEbdqy9gnJm3ctObGDbxRDAAqBOcP/xN0ulKP3Lm5uV/u2zVo4IhePfuFBIc82KN3zH0PrPnkQ2mEGjVqDRk8MigwiCraVOO+cOEc9Tz87YHk5L8njJ8aEVGtTp16kyZOz8i4xQAAKgDngZvjS//hgBSI8/LyKCJLfVreedelS/Fp6Wnix4YNm0iDgoKCMzMzqCMx8U9fX99q1SLF/hTTw8MjGABABeD5i5NiTXni5FE2/VNTblAFnJkzNgq1/vT0ND8/f3kfHx9fVjZwvRYAPMrzFyerVA2jv1OfmUUpEXn/8PBqTqYKDg7Jzs6S98nKymRlA3dOAoBHFXvLe6lHqZo1onx8fKijVcs2Yp/U1BSq6fv7+zuZqlpEZE5ODmVU6tWLpo/x8Rf+/fcfBgBQAThtVaIri4uTFKBHDB9LVyNPnz5Jye5Dh/dPmz6+2HsgO3bsbDAYFi+ZT+GbQvbc+TODLXkVAIByz2mOm+f4MrkBZ0D/YfXrN1y/Me6XX34KCAi8o2mLqVNnO58kMDDwlQVLV6x4++Fenekq5ZgnJn29/wsGAFABcE4uP375SXL8r+nDXohmILP65fin3sQ6AQCP8XyOGwAAXOLO5oBTpz0p3h1jw2Qy0Zy89MrftfaTbSEhlZibrN8Qt2FDnPIwOgg5+DkrP9wYEeGsEQsAgHo4r3ELes75HTpWnp85Ly8/T3FQbm6u2HTEnhujNunZs1+XLt0UB91KTw8KDlYcJD78BABAE5zXuDmT4MKtk2oIf0GBQfRPcVBkteoMAED78Ooyl+FJtwDgWXh1mctwMAMAz0KrEgAAjcEbcAAANMZZ4NbpBL3OhVYlAABQBpwFbp7nTGXwQG4AAHAFWpUAAGiMKl4WDAAAJYfmgAAAGuMscOv1JoO3ngEAgJo4azQSVNnbpVveK4LrVzL1OJYBgEc5C9zte1TlTcK1hHQGhU4fvuEbhCu2AOBJxTTTrt3Y99CnyQwKJSXkPTg6ggEAeA5X7L2Rxw/cOPZlaqM2QW26VdyAlZGRfXR3yvXz2cNerB0Y4s0AADyHK8lN7Qe3XD//S6Yxl1HGWxybkgWCwzkyQcolCJZRi1h9pm/mHA+1mo/SN1qGc8zhDBQmofML25y97RLSJ/M3W02lMy+nbwDXe3z1KhF+DADAoziXnkbyz195YnJF/jIZjpPNhON0FN4tn8zxUBZ8LUFWkOK+SPpuzhJliz6KoxZNa/6/6EsKxrCKr/L5i3Sc7cuOOU4vCCbrPgULL0V5ncB4myS2yRRWC/EaANSCw2OkAAC0BXdOAgBoDAI3AIDGIHADAGgMAjcAgMYgcAMAaAwCNwCAxvw/AAAA//81BbBAAAAABklEQVQDAP/EcrlRdUNfAAAAAElFTkSuQmCC",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the graph\n",
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I have a question Welcome to Acme Support! [Routed to General]\n"
     ]
    }
   ],
   "source": [
    "# Try the other path — general handler\n",
    "result = graph.invoke({\"message\": \"Hello, I have a question\"})\n",
    "print(result[\"message\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What we have:** A basic workflow that routes requests.\n",
    "\n",
    "**Problem:** It's just string manipulation. We need an LLM to understand users.\n",
    "\n",
    "---\n",
    "## Step 2: Add an LLM (Chain)\n",
    "\n",
    "**Problem from Step 1:** Our nodes are hardcoded. We need the LLM to generate intelligent responses.\n",
    "\n",
    "**Solution:** Use **MessagesState** (a pre-built state with a messages list) and a chat model.\n",
    "\n",
    "### Architecture\n",
    "\n",
    "```mermaid\n",
    "%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#E3F2FD', 'primaryTextColor': '#0D47A1', 'primaryBorderColor': '#2196F3', 'lineColor': '#2196F3'}}}%%\n",
    "graph LR\n",
    "    START([\"__start__\"]) --> chatbot[\"chatbot\\n(LLM call)\"]\n",
    "    chatbot --> END([\"__end__\"])\n",
    "```\n",
    "\n",
    "**Why MessagesState?** It uses the `add_messages` **reducer** — when a node returns messages, they get **appended** to the list instead of replacing it. This is critical for conversation history.\n",
    "\n",
    "```python\n",
    "# Under the hood, MessagesState is:\n",
    "class MessagesState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]  # add_messages = append reducer\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# MessagesState has a built-in `messages` list with an `add_messages` reducer\n",
    "# This means new messages APPEND instead of overwrite\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "def chatbot(state: MessagesState):\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}  # Appended, not overwritten!\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"chatbot\", chatbot)\n",
    "builder.add_edge(START, \"chatbot\")\n",
    "builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "result = graph.invoke({\"messages\": [HumanMessage(content=\"Hi, I need support\")]})\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What we have:** LLM-powered chatbot.\n",
    "\n",
    "**Problem:** It can only talk. It can't look up orders, search docs, or take actions.\n",
    "\n",
    "---\n",
    "## Step 3: Add Tools — The Router Pattern\n",
    "\n",
    "**Problem from Step 2:** The LLM can only generate text. We need it to call functions.\n",
    "\n",
    "**Solution:** **Bind tools** to the LLM. Add a **ToolNode** to execute them. Use **tools_condition** to route.\n",
    "\n",
    "### Architecture\n",
    "\n",
    "```mermaid\n",
    "%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#FFF3E0', 'primaryTextColor': '#E65100', 'primaryBorderColor': '#FF9800', 'lineColor': '#FF9800'}}}%%\n",
    "graph LR\n",
    "    START([\"__start__\"]) --> assistant[\"assistant\\n(LLM + tools)\"]\n",
    "    assistant -->|\"tool_call\"| tools[\"tools\\n(ToolNode)\"]\n",
    "    assistant -->|\"no tool_call\"| END([\"__end__\"])\n",
    "    tools --> END\n",
    "```\n",
    "\n",
    "This is the **Router** pattern: the LLM decides whether to call a tool or respond directly.\n",
    "\n",
    "**Problem:** After the tool runs, the result goes to END. The LLM **never sees the tool output!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Check orders for Alice\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  search_orders (call_snLBds1C2QhxUYdycqAeaDCO)\n",
      " Call ID: call_snLBds1C2QhxUYdycqAeaDCO\n",
      "  Args:\n",
      "    customer_name: Alice\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: search_orders\n",
      "\n",
      "Order #123: Laptop, arriving tomorrow\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "# Define tools the agent can use\n",
    "@tool\n",
    "def search_orders(customer_name: str) -> str:\n",
    "    \"\"\"Search for customer orders by name.\"\"\"\n",
    "    orders = {\"Alice\": \"Order #123: Laptop, arriving tomorrow\",\n",
    "              \"Bob\": \"Order #456: Mouse, delivered\"}\n",
    "    return orders.get(customer_name, \"No orders found\")\n",
    "\n",
    "@tool\n",
    "def check_shipping(order_id: str) -> str:\n",
    "    \"\"\"Check shipping status for an order.\"\"\"\n",
    "    return f\"Order {order_id}: In transit, ETA 2 days\"\n",
    "\n",
    "tools = [search_orders, check_shipping]\n",
    "llm_with_tools = ChatOpenAI(model=\"gpt-4o\").bind_tools(tools)\n",
    "\n",
    "def assistant(state: MessagesState):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))  # Pre-built: executes tool calls\n",
    "\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    tools_condition  # Routes to \"tools\" if LLM made a tool call, else END\n",
    ")\n",
    "builder.add_edge(\"tools\", END)  # After tool runs, END\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "result = graph.invoke({\"messages\": [HumanMessage(content=\"Check orders for Alice\")]})\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the Router pattern\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the LLM calls the tool, but the tool result goes straight to END. The LLM never gets to reason about the tool output!\n",
    "\n",
    "---\n",
    "## Step 4: The ReAct Agent Loop\n",
    "\n",
    "**Problem from Step 3:** Tool results go to END — the LLM never sees them and can't reason about them.\n",
    "\n",
    "**Solution:** Loop the tool output **back to the assistant**. This creates the **ReAct pattern**: Reason -> Act -> Observe -> Repeat.\n",
    "\n",
    "### Architecture\n",
    "\n",
    "```mermaid\n",
    "%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#F3E5F5', 'primaryTextColor': '#4A148C', 'primaryBorderColor': '#9C27B0', 'lineColor': '#9C27B0'}}}%%\n",
    "graph LR\n",
    "    START([\"__start__\"]) --> assistant[\"assistant\\n(Reason)\"]\n",
    "    assistant -->|\"tool_call\"| tools[\"tools\\n(Act)\"]\n",
    "    assistant -->|\"no tool_call\"| END([\"__end__\"])\n",
    "    tools -->|\"Observe result\"| assistant\n",
    "```\n",
    "\n",
    "**The ReAct loop:**\n",
    "1. User asks question\n",
    "2. Assistant decides: call a tool or respond\n",
    "3. If tool call -> tool executes -> result goes **back to assistant**\n",
    "4. Assistant sees result, decides: call another tool or respond\n",
    "5. Repeat until assistant responds without tool calls -> END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Check my orders. My name is Alice. Then check the shipping.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  search_orders (call_wGRBGLNjatQqxEoh2sQRlvoI)\n",
      " Call ID: call_wGRBGLNjatQqxEoh2sQRlvoI\n",
      "  Args:\n",
      "    customer_name: Alice\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: search_orders\n",
      "\n",
      "Order #123: Laptop, arriving tomorrow\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  check_shipping (call_l3ho035NvsDReoesImGv5SA5)\n",
      " Call ID: call_l3ho035NvsDReoesImGv5SA5\n",
      "  Args:\n",
      "    order_id: 123\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: check_shipping\n",
      "\n",
      "Order 123: In transit, ETA 2 days\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I found your order: a Laptop, expected to arrive tomorrow. However, the current shipping status shows it's in transit with an estimated arrival time of 2 days.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "sys_msg = SystemMessage(content=\"You are a helpful customer support agent for Acme Corp.\")\n",
    "\n",
    "def assistant(state: MessagesState):\n",
    "    return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\"assistant\", tools_condition)\n",
    "builder.add_edge(\"tools\", \"assistant\")  # KEY CHANGE: loop back!\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "# Now the agent can chain multiple tool calls\n",
    "result = graph.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"Check my orders. My name is Alice. Then check the shipping.\")]\n",
    "})\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the ReAct loop\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What we have:** A real agent that reasons and acts.\n",
    "\n",
    "**Problem:** It forgets everything between calls.\n",
    "\n",
    "---\n",
    "## Step 5: Add Memory (Checkpointer)\n",
    "\n",
    "**Problem from Step 4:** Each `invoke()` is independent. The agent forgets the entire conversation.\n",
    "\n",
    "**Solution:** Add a **checkpointer** that saves state after every step. Use **thread_id** to identify conversations.\n",
    "\n",
    "### Architecture\n",
    "\n",
    "```mermaid\n",
    "%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#E8F5E9', 'primaryTextColor': '#1B5E20', 'primaryBorderColor': '#4CAF50', 'lineColor': '#4CAF50'}}}%%\n",
    "graph TD\n",
    "    subgraph \"Thread: alice-support-1\"\n",
    "        A[\"Message 1\"] --> B[\"Checkpoint 1\"]\n",
    "        B --> C[\"Message 2\"]\n",
    "        C --> D[\"Checkpoint 2\"]\n",
    "        D --> E[\"Message 3\"]\n",
    "        E --> F[\"Checkpoint 3\"]\n",
    "    end\n",
    "    subgraph \"Thread: bob-support-1\"\n",
    "        G[\"Message 1\"] --> H[\"Checkpoint 1\"]\n",
    "        H --> I[\"Message 2\"]\n",
    "        I --> J[\"Checkpoint 2\"]\n",
    "    end\n",
    "```\n",
    "\n",
    "**How it works:**\n",
    "- `MemorySaver` saves a **checkpoint** (full state snapshot) after every graph step\n",
    "- `thread_id` identifies which conversation to load/save\n",
    "- Different `thread_id` = different conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# Same graph as Step 4, but compiled with a checkpointer\n",
    "graph = builder.compile(checkpointer=MemorySaver())\n",
    "\n",
    "# thread_id identifies the conversation\n",
    "config = {\"configurable\": {\"thread_id\": \"alice-support-1\"}}\n",
    "\n",
    "# First message\n",
    "result = graph.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Hi, I'm Alice. Check my orders.\")]},\n",
    "    config\n",
    ")\n",
    "print(\"--- First message ---\")\n",
    "print(result[\"messages\"][-1].content)\n",
    "\n",
    "# Second message — REMEMBERS because same thread_id\n",
    "result = graph.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What was my order number?\")]},\n",
    "    config  # Same thread = same memory\n",
    ")\n",
    "print(\"\\n--- Second message (remembers!) ---\")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different thread = no memory of previous conversation\n",
    "config_new = {\"configurable\": {\"thread_id\": \"bob-support-1\"}}\n",
    "result = graph.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What was my order number?\")]},\n",
    "    config_new\n",
    ")\n",
    "print(\"--- Different thread (no memory) ---\")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What we have:** Agent with conversation memory.\n",
    "\n",
    "**Problem:** We need to track more than just messages — like customer tier, escalation status, etc.\n",
    "\n",
    "---\n",
    "## Step 6: Custom State, Schemas & Reducers\n",
    "\n",
    "**Problem from Step 5:** MessagesState only has `messages`. We need custom fields (customer info, ticket status) and proper validation.\n",
    "\n",
    "**Solution:** Define **custom state** with extra keys. Use **reducers** to control how updates work. Use **Pydantic** for validation. Use **separate input/output schemas** to hide internal state.\n",
    "\n",
    "### Reducer Behavior\n",
    "\n",
    "```mermaid\n",
    "%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#FFFDE7', 'primaryTextColor': '#F57F17', 'primaryBorderColor': '#FFC107', 'lineColor': '#FFC107'}}}%%\n",
    "graph TD\n",
    "    subgraph \"Default: Overwrite\"\n",
    "        A1[\"customer_name = 'Alice'\"] -->|\"return {'customer_name': 'Bob'}\"| A2[\"customer_name = 'Bob'\"]\n",
    "    end\n",
    "    subgraph \"Reducer: operator.add (Append)\"\n",
    "        B1[\"action_log = ['searched']\"] -->|\"return {'action_log': ['called']}\"| B2[\"action_log = ['searched', 'called']\"]\n",
    "    end\n",
    "    subgraph \"Reducer: add_messages (Append)\"\n",
    "        C1[\"messages = [msg1]\"] -->|\"return {'messages': [msg2]}\"| C2[\"messages = [msg1, msg2]\"]\n",
    "    end\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Custom State Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "\n",
    "class SupportState(MessagesState):\n",
    "    # Extra keys beyond messages\n",
    "    customer_name: str\n",
    "    customer_tier: str  # \"standard\" or \"premium\"\n",
    "    escalated: bool\n",
    "\n",
    "print(\"SupportState fields:\", list(SupportState.__annotations__.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Reducers — Control How State Updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated\n",
    "\n",
    "class StateWithReducers(MessagesState):\n",
    "    customer_name: str                                    # Default: overwrite\n",
    "    action_log: Annotated[list, operator.add]             # Reducer: append lists\n",
    "    escalated: bool\n",
    "\n",
    "# Custom reducer for edge cases\n",
    "def safe_add(left: list | None, right: list | None) -> list:\n",
    "    \"\"\"Handles None values gracefully.\"\"\"\n",
    "    return (left or []) + (right or [])\n",
    "\n",
    "class StateWithSafeReducer(MessagesState):\n",
    "    action_log: Annotated[list, safe_add]\n",
    "\n",
    "print(\"Reducer demo: operator.add([1,2], [3,4]) =\", operator.add([1, 2], [3, 4]))\n",
    "print(\"Safe reducer: safe_add(None, ['action']) =\", safe_add(None, [\"action\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Pydantic Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, field_validator\n",
    "\n",
    "class ValidatedState(BaseModel):\n",
    "    customer_name: str\n",
    "    customer_tier: str\n",
    "\n",
    "    @field_validator('customer_tier')\n",
    "    def validate_tier(cls, v):\n",
    "        if v not in [\"standard\", \"premium\"]:\n",
    "            raise ValueError(\"Tier must be 'standard' or 'premium'\")\n",
    "        return v\n",
    "\n",
    "# This works\n",
    "valid = ValidatedState(customer_name=\"Alice\", customer_tier=\"premium\")\n",
    "print(f\"Valid: {valid}\")\n",
    "\n",
    "# This raises a validation error\n",
    "try:\n",
    "    invalid = ValidatedState(customer_name=\"Alice\", customer_tier=\"gold\")\n",
    "except ValueError as e:\n",
    "    print(f\"Validation error (expected): {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Input/Output Schemas — Hide Internal State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "\n",
    "class InputState(TypedDict):   # What the caller provides\n",
    "    messages: list\n",
    "\n",
    "class OutputState(TypedDict):  # What the caller gets back\n",
    "    messages: list\n",
    "    resolution: str\n",
    "\n",
    "class FullState(InputState):   # Internal — caller never sees this\n",
    "    customer_tier: str\n",
    "    escalated: bool\n",
    "    action_log: list\n",
    "\n",
    "# Use separate schemas:\n",
    "# builder = StateGraph(FullState, input=InputState, output=OutputState)\n",
    "print(\"InputState keys:\", list(InputState.__annotations__.keys()))\n",
    "print(\"OutputState keys:\", list(OutputState.__annotations__.keys()))\n",
    "print(\"FullState keys:\", list(FullState.__annotations__.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Warning:** Parallel nodes writing to the same key will **FAIL** without a reducer! If two nodes run in parallel and both write to the same field, you need a reducer to merge the results.\n",
    "\n",
    "**What we have:** Rich state with validation and clean API boundaries.\n",
    "\n",
    "**Problem:** Long conversations use too many tokens (expensive and slow).\n",
    "\n",
    "---\n",
    "## Step 7: Manage Long Conversations\n",
    "\n",
    "**Problem from Step 6:** After 20+ messages, the context is huge. Token costs skyrocket, responses slow down.\n",
    "\n",
    "**Solution:** Three strategies: **trim**, **filter**, or **summarize** old messages.\n",
    "\n",
    "### Strategy Comparison\n",
    "\n",
    "```mermaid\n",
    "%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#FCE4EC', 'primaryTextColor': '#880E4F', 'primaryBorderColor': '#E91E63', 'lineColor': '#E91E63'}}}%%\n",
    "graph TD\n",
    "    LONG[\"20+ messages\\n(expensive!)\"] --> TRIM[\"Trim\\nKeep last N tokens\"]\n",
    "    LONG --> FILTER[\"Filter\\nRemove tool messages\"]\n",
    "    LONG --> SUMMARIZE[\"Summarize\\nCompress into summary\"]\n",
    "    TRIM --> RESULT1[\"Fast but loses context\"]\n",
    "    FILTER --> RESULT2[\"Moderate savings\"]\n",
    "    SUMMARIZE --> RESULT3[\"Best of both worlds\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Trim Messages (by token count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import trim_messages, AIMessage\n",
    "\n",
    "# Create a sample long conversation\n",
    "long_conversation = [\n",
    "    SystemMessage(content=\"You are a support agent.\"),\n",
    "    HumanMessage(content=\"I need help with billing\"),\n",
    "    AIMessage(content=\"I'd be happy to help with billing.\"),\n",
    "    HumanMessage(content=\"My account number is 12345\"),\n",
    "    AIMessage(content=\"I found your account. What's the issue?\"),\n",
    "    HumanMessage(content=\"I was charged twice for my subscription\"),\n",
    "    AIMessage(content=\"I see the duplicate charge. Let me fix that.\"),\n",
    "    HumanMessage(content=\"When will the refund appear?\"),\n",
    "]\n",
    "\n",
    "# Trim to keep only the most recent messages (by token count)\n",
    "trimmed = trim_messages(\n",
    "    long_conversation,\n",
    "    max_tokens=100,\n",
    "    token_counter=llm,     # Use the LLM's tokenizer\n",
    "    strategy=\"last\",       # Keep most recent\n",
    "    include_system=True    # Always keep system message\n",
    ")\n",
    "\n",
    "print(f\"Original: {len(long_conversation)} messages\")\n",
    "print(f\"Trimmed: {len(trimmed)} messages\")\n",
    "for m in trimmed:\n",
    "    print(f\"  [{m.type}] {m.content[:60]}...\" if len(m.content) > 60 else f\"  [{m.type}] {m.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Filter Messages (by type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_tool_messages(messages: list) -> list:\n",
    "    \"\"\"Remove tool call/result messages to save tokens.\"\"\"\n",
    "    return [m for m in messages if m.type in (\"human\", \"ai\", \"system\") and not getattr(m, 'tool_calls', None)]\n",
    "\n",
    "# Demo\n",
    "filtered = filter_tool_messages(long_conversation)\n",
    "print(f\"Filtered: {len(filtered)} messages (from {len(long_conversation)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Summarize (best of both worlds)\n",
    "\n",
    "Keep a running summary so no context is truly lost.\n",
    "\n",
    "```mermaid\n",
    "%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#E8F5E9', 'primaryTextColor': '#1B5E20', 'primaryBorderColor': '#4CAF50', 'lineColor': '#4CAF50'}}}%%\n",
    "graph LR\n",
    "    START([\"__start__\"]) --> assistant[\"assistant\"]\n",
    "    assistant -->|\"tool_call\"| tools[\"tools\"]\n",
    "    assistant -->|\"no tool_call, msgs > 6\"| summarize[\"summarize\"]\n",
    "    assistant -->|\"no tool_call, msgs <= 6\"| END([\"__end__\"])\n",
    "    tools --> assistant\n",
    "    summarize --> END\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import RemoveMessage\n",
    "\n",
    "class SummarizedState(MessagesState):\n",
    "    summary: str  # Holds conversation summary\n",
    "\n",
    "def summarize_conversation(state: SummarizedState):\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    if summary:\n",
    "        summary_prompt = (\n",
    "            f\"Existing summary: {summary}\\n\\n\"\n",
    "            \"Extend the summary with the new messages above:\"\n",
    "        )\n",
    "    else:\n",
    "        summary_prompt = \"Create a summary of the conversation above:\"\n",
    "\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=summary_prompt)]\n",
    "    new_summary = ChatOpenAI(model=\"gpt-4o\").invoke(messages).content\n",
    "\n",
    "    # Delete all but the 2 most recent messages\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "    return {\"summary\": new_summary, \"messages\": delete_messages}\n",
    "\n",
    "def should_summarize(state: SummarizedState):\n",
    "    \"\"\"Trigger summarization when conversation gets long.\"\"\"\n",
    "    if len(state[\"messages\"]) > 6:\n",
    "        return \"summarize\"\n",
    "    return END\n",
    "\n",
    "print(\"Summarization functions defined.\")\n",
    "print(\"This pattern keeps a running summary while trimming old messages.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What we have:** Efficient long conversations.\n",
    "\n",
    "**Problem:** MemorySaver stores everything in RAM — restart the app and all conversations are gone.\n",
    "\n",
    "---\n",
    "## Step 8: Persistent Memory (External Storage)\n",
    "\n",
    "**Problem from Step 7:** `MemorySaver` is in-memory. Server restart = all conversations lost.\n",
    "\n",
    "**Solution:** Use a **database-backed checkpointer** for production.\n",
    "\n",
    "### Checkpointer Options\n",
    "\n",
    "```mermaid\n",
    "%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#E3F2FD', 'primaryTextColor': '#0D47A1', 'primaryBorderColor': '#2196F3', 'lineColor': '#2196F3'}}}%%\n",
    "graph LR\n",
    "    DEV[\"Development\"] --> MEM[\"MemorySaver\\n(RAM)\"]\n",
    "    SINGLE[\"Single Server\"] --> SQL[\"SqliteSaver\\n(disk file)\"]\n",
    "    MULTI[\"Multi Server\"] --> PG[\"PostgresSaver\\n(database)\"]\n",
    "```\n",
    "\n",
    "| Checkpointer | Persists where | When to use |\n",
    "|---|---|---|\n",
    "| `MemorySaver` | RAM (lost on restart) | Development, testing |\n",
    "| `SqliteSaver` | SQLite file on disk | Single-server production |\n",
    "| `PostgresSaver` | PostgreSQL database | Multi-server production |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Development: RAM (fast, temporary)\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "memory_checkpointer = MemorySaver()\n",
    "print(\"MemorySaver: In-memory, fast, data lost on restart\")\n",
    "\n",
    "# Production (single server): SQLite\n",
    "# from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "# with SqliteSaver.from_conn_string(\"checkpoints.db\") as checkpointer:\n",
    "#     graph = builder.compile(checkpointer=checkpointer)\n",
    "print(\"SqliteSaver: File-based, persistent, single server\")\n",
    "\n",
    "# Production (multi-server): PostgreSQL\n",
    "# from langgraph.checkpoint.postgres import PostgresSaver\n",
    "# with PostgresSaver.from_conn_string(\"postgresql://...\") as checkpointer:\n",
    "#     graph = builder.compile(checkpointer=checkpointer)\n",
    "print(\"PostgresSaver: Database-backed, distributed, multi-server\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What we have:** Persistent conversations that survive restarts.\n",
    "\n",
    "**Problem:** Users stare at a blank screen waiting for the full response.\n",
    "\n",
    "---\n",
    "## Step 9: Streaming\n",
    "\n",
    "**Problem from Step 8:** `invoke()` waits for the entire graph to finish. Users see nothing until the end.\n",
    "\n",
    "**Solution:** **Stream** tokens and state updates in real-time.\n",
    "\n",
    "### Streaming Modes\n",
    "\n",
    "```mermaid\n",
    "%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#FFF3E0', 'primaryTextColor': '#E65100', 'primaryBorderColor': '#FF9800', 'lineColor': '#FF9800'}}}%%\n",
    "graph TD\n",
    "    STREAM[\"graph.stream()\"] --> VALUES[\"stream_mode='values'\\nFull state after each node\"]\n",
    "    STREAM --> MESSAGES[\"stream_mode='messages'\\nIndividual token chunks\"]\n",
    "    STREAM --> ASYNC[\"graph.astream()\\nAsync streaming\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Stream Full State After Each Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuild the ReAct agent with memory for streaming demo\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"assistant\", lambda state: {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]})\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\"assistant\", tools_condition)\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "graph = builder.compile(checkpointer=MemorySaver())\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"stream-demo\"}}\n",
    "\n",
    "print(\"=== Stream Mode: values (full state after each node) ===\")\n",
    "for event in graph.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"Check orders for Alice\")]},\n",
    "    config,\n",
    "    stream_mode=\"values\"  # Full state after each node\n",
    "):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Stream Individual Tokens (typing effect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config2 = {\"configurable\": {\"thread_id\": \"stream-demo-2\"}}\n",
    "\n",
    "print(\"=== Stream Mode: messages (individual token chunks) ===\")\n",
    "for event in graph.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"Tell me about Acme Corp's return policy in 2 sentences.\")]},\n",
    "    config2,\n",
    "    stream_mode=\"messages\"  # Individual message chunks\n",
    "):\n",
    "    msg, metadata = event\n",
    "    if msg.content and metadata.get(\"langgraph_node\") == \"assistant\":\n",
    "        print(msg.content, end=\"\", flush=True)  # Real-time typing\n",
    "print()  # newline at end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What we have:** Real-time streaming responses.\n",
    "\n",
    "**Problem:** The agent executes tools automatically — what if a tool sends an email or makes a purchase?\n",
    "\n",
    "---\n",
    "## Step 10: Human-in-the-Loop (Breakpoints)\n",
    "\n",
    "**Problem from Step 9:** Tools execute without approval. Dangerous for actions like sending emails, refunding money, or deleting data.\n",
    "\n",
    "**Solution:** Add **breakpoints** to pause before tool execution. The human reviews, then resumes.\n",
    "\n",
    "### Flow with Breakpoint\n",
    "\n",
    "```mermaid\n",
    "%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#FFEBEE', 'primaryTextColor': '#B71C1C', 'primaryBorderColor': '#F44336', 'lineColor': '#F44336'}}}%%\n",
    "graph LR\n",
    "    START([\"__start__\"]) --> assistant[\"assistant\"]\n",
    "    assistant -->|\"tool_call\"| PAUSE{{\"PAUSE\\nHuman Review\"}}\n",
    "    PAUSE -->|\"Approve\"| tools[\"tools\"]\n",
    "    PAUSE -->|\"Edit/Reject\"| assistant\n",
    "    assistant -->|\"no tool_call\"| END([\"__end__\"])\n",
    "    tools --> assistant\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1 Static Breakpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile with interrupt_before\n",
    "graph_with_hitl = builder.compile(\n",
    "    checkpointer=MemorySaver(),\n",
    "    interrupt_before=[\"tools\"]  # PAUSE before running any tool\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"approval-demo\"}}\n",
    "\n",
    "# Step 1: Run until breakpoint\n",
    "print(\"=== Step 1: Run until breakpoint ===\")\n",
    "for event in graph_with_hitl.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"Check orders for Alice\")]},\n",
    "    config,\n",
    "    stream_mode=\"values\"\n",
    "):\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "# Step 2: Inspect what's pending\n",
    "print(\"\\n=== Step 2: Inspect pending state ===\")\n",
    "state = graph_with_hitl.get_state(config)\n",
    "print(f\"Next node: {state.next}\")\n",
    "print(f\"Pending tool calls: {state.values['messages'][-1].tool_calls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Human approves -> resume\n",
    "print(\"=== Step 3: Human approves, resuming... ===\")\n",
    "for event in graph_with_hitl.stream(None, config, stream_mode=\"values\"):  # None = continue\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 Edit State Before Resuming\n",
    "\n",
    "The human can **modify** what the agent is about to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_edit = {\"configurable\": {\"thread_id\": \"edit-demo\"}}\n",
    "\n",
    "# Run until breakpoint\n",
    "for event in graph_with_hitl.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"Check orders for Bob\")]},\n",
    "    config_edit,\n",
    "    stream_mode=\"values\"\n",
    "):\n",
    "    pass\n",
    "\n",
    "print(\"Paused before tools. Let's edit the state...\")\n",
    "\n",
    "# Inject a human message to change course\n",
    "graph_with_hitl.update_state(\n",
    "    config_edit,\n",
    "    {\"messages\": [HumanMessage(content=\"Actually, check orders for Alice instead.\")]}\n",
    ")\n",
    "\n",
    "# Resume with modified state\n",
    "print(\"\\nResuming with edited state...\")\n",
    "for event in graph_with_hitl.stream(None, config_edit, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3 Dynamic Breakpoints (inside nodes)\n",
    "\n",
    "Pause conditionally from **inside** a node using `interrupt()`:\n",
    "\n",
    "```python\n",
    "from langgraph.types import interrupt\n",
    "\n",
    "@tool\n",
    "def refund_order(order_id: str) -> str:\n",
    "    \"\"\"Process a refund for an order. Requires human approval.\"\"\"\n",
    "    answer = interrupt({\"question\": f\"Approve refund for {order_id}? (yes/no)\"})\n",
    "    if answer.lower() != \"yes\":\n",
    "        return \"Refund cancelled by human.\"\n",
    "    return f\"Refund processed for {order_id}\"\n",
    "```\n",
    "\n",
    "**What we have:** Safe agent with human oversight.\n",
    "\n",
    "**Problem:** Something went wrong 5 steps ago. How do we debug it?\n",
    "\n",
    "---\n",
    "## Step 11: Time Travel\n",
    "\n",
    "**Problem from Step 10:** The agent made a mistake earlier in the conversation. We need to go back and try a different path.\n",
    "\n",
    "**Solution:** Browse the **state history** and **fork** from any past checkpoint.\n",
    "\n",
    "### Time Travel Visualization\n",
    "\n",
    "```mermaid\n",
    "%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#E8EAF6', 'primaryTextColor': '#1A237E', 'primaryBorderColor': '#3F51B5', 'lineColor': '#3F51B5'}}}%%\n",
    "graph TD\n",
    "    S1[\"Step 1: User asks\"] --> S2[\"Step 2: Agent calls tool A\"]\n",
    "    S2 --> S3[\"Step 3: Tool A result\"]\n",
    "    S3 --> S4[\"Step 4: Agent responds (wrong!)\"]\n",
    "    S3 -.->|\"Fork here!\"| S4B[\"Step 4B: Try different tool\"]\n",
    "    S4B --> S5B[\"Step 5B: Better response\"]\n",
    "    \n",
    "    style S4 fill:#FFCDD2,stroke:#F44336\n",
    "    style S4B fill:#C8E6C9,stroke:#4CAF50\n",
    "    style S5B fill:#C8E6C9,stroke:#4CAF50\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1 Browse History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using our approval-demo thread which has history\n",
    "config = {\"configurable\": {\"thread_id\": \"approval-demo\"}}\n",
    "\n",
    "print(\"=== State History ===\")\n",
    "for state in graph_with_hitl.get_state_history(config):\n",
    "    print(f\"Step {state.metadata.get('step', '?')}: next={state.next}, \"\n",
    "          f\"messages={len(state.values.get('messages', []))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2 Fork From a Past State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all history\n",
    "all_states = list(graph_with_hitl.get_state_history(config))\n",
    "print(f\"Total checkpoints: {len(all_states)}\")\n",
    "\n",
    "if len(all_states) >= 2:\n",
    "    # Go back to an earlier state\n",
    "    past_state = all_states[-2]  # Second from the beginning\n",
    "    print(f\"\\nForking from step {past_state.metadata.get('step', '?')}...\")\n",
    "    \n",
    "    # Modify that past state and run from there\n",
    "    graph_with_hitl.update_state(\n",
    "        past_state.config,\n",
    "        {\"messages\": [HumanMessage(content=\"Actually, check shipping for order 456\")]}\n",
    "    )\n",
    "    \n",
    "    # This creates a NEW timeline from that point\n",
    "    print(\"Running from forked state...\")\n",
    "    for event in graph_with_hitl.stream(None, past_state.config, stream_mode=\"values\"):\n",
    "        event[\"messages\"][-1].pretty_print()\n",
    "else:\n",
    "    print(\"Not enough history to demo forking.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use cases:**\n",
    "- **Debug:** See exactly what the agent did at each step\n",
    "- **Retry:** Go back and try a different tool call\n",
    "- **A/B test:** Fork from the same point and compare different paths\n",
    "\n",
    "**What we have:** Full debuggability and replay.\n",
    "\n",
    "**Problem:** Some tasks are independent (search orders + check FAQ) but run sequentially. Slow!\n",
    "\n",
    "---\n",
    "## Step 12: Parallel Execution, Sub-graphs & Map-Reduce\n",
    "\n",
    "**Problem from Step 11:** Independent tasks run one after another. Wastes time.\n",
    "\n",
    "### 12.1 Static Parallelism\n",
    "\n",
    "```mermaid\n",
    "%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#F3E5F5', 'primaryTextColor': '#4A148C', 'primaryBorderColor': '#9C27B0', 'lineColor': '#9C27B0'}}}%%\n",
    "graph TD\n",
    "    classify[\"classify\"] --> search_orders[\"search_orders\"]\n",
    "    classify --> search_faq[\"search_faq\"]\n",
    "    classify --> check_history[\"check_history\"]\n",
    "    search_orders --> aggregate[\"aggregate\"]\n",
    "    search_faq --> aggregate\n",
    "    check_history --> aggregate\n",
    "```\n",
    "\n",
    "Multiple edges from the same source = parallel execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: Static Parallelism\n",
    "from typing import Annotated\n",
    "import operator\n",
    "\n",
    "class ParallelState(TypedDict):\n",
    "    query: str\n",
    "    results: Annotated[list, operator.add]  # Must use reducer for parallel writes!\n",
    "\n",
    "def classify(state: ParallelState):\n",
    "    return {}  # Just passes through\n",
    "\n",
    "def search_orders_node(state: ParallelState):\n",
    "    return {\"results\": [f\"Orders result for: {state['query']}\"]}\n",
    "\n",
    "def search_faq_node(state: ParallelState):\n",
    "    return {\"results\": [f\"FAQ result for: {state['query']}\"]}\n",
    "\n",
    "def check_history_node(state: ParallelState):\n",
    "    return {\"results\": [f\"History result for: {state['query']}\"]}\n",
    "\n",
    "def aggregate(state: ParallelState):\n",
    "    return {\"results\": [f\"\\nAggregated {len(state['results'])} results\"]}\n",
    "\n",
    "parallel_builder = StateGraph(ParallelState)\n",
    "parallel_builder.add_node(\"classify\", classify)\n",
    "parallel_builder.add_node(\"search_orders\", search_orders_node)\n",
    "parallel_builder.add_node(\"search_faq\", search_faq_node)\n",
    "parallel_builder.add_node(\"check_history\", check_history_node)\n",
    "parallel_builder.add_node(\"aggregate\", aggregate)\n",
    "\n",
    "parallel_builder.add_edge(START, \"classify\")\n",
    "parallel_builder.add_edge(\"classify\", \"search_orders\")    # These three run\n",
    "parallel_builder.add_edge(\"classify\", \"search_faq\")       # in PARALLEL\n",
    "parallel_builder.add_edge(\"classify\", \"check_history\")\n",
    "parallel_builder.add_edge(\"search_orders\", \"aggregate\")   # All must complete\n",
    "parallel_builder.add_edge(\"search_faq\", \"aggregate\")      # before aggregate\n",
    "parallel_builder.add_edge(\"check_history\", \"aggregate\")\n",
    "parallel_builder.add_edge(\"aggregate\", END)\n",
    "\n",
    "parallel_graph = parallel_builder.compile()\n",
    "result = parallel_graph.invoke({\"query\": \"laptop order\", \"results\": []})\n",
    "print(\"Results:\")\n",
    "for r in result[\"results\"]:\n",
    "    print(f\"  - {r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize parallel execution\n",
    "display(Image(parallel_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.2 Sub-graphs (Reusable Workflows)\n",
    "\n",
    "Complex workflows have reusable parts. Sub-graphs are like functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a reusable order-lookup sub-graph\n",
    "class OrderState(TypedDict):\n",
    "    order_id: str\n",
    "    order_details: str\n",
    "\n",
    "def validate_order(state: OrderState):\n",
    "    oid = state[\"order_id\"]\n",
    "    return {\"order_details\": f\"Order {oid} validated\"}\n",
    "\n",
    "def fetch_details(state: OrderState):\n",
    "    return {\"order_details\": state[\"order_details\"] + \" | Details: Laptop, $999\"}\n",
    "\n",
    "sub_builder = StateGraph(OrderState)\n",
    "sub_builder.add_node(\"validate_order\", validate_order)\n",
    "sub_builder.add_node(\"fetch_details\", fetch_details)\n",
    "sub_builder.add_edge(START, \"validate_order\")\n",
    "sub_builder.add_edge(\"validate_order\", \"fetch_details\")\n",
    "sub_builder.add_edge(\"fetch_details\", END)\n",
    "order_lookup_graph = sub_builder.compile()\n",
    "\n",
    "# Test the sub-graph independently\n",
    "result = order_lookup_graph.invoke({\"order_id\": \"123\", \"order_details\": \"\"})\n",
    "print(f\"Sub-graph result: {result['order_details']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the sub-graph\n",
    "display(Image(order_lookup_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.3 Map-Reduce (Dynamic Parallelism with Send)\n",
    "\n",
    "**Unknown** number of parallel tasks at build time? Use the **Send** API.\n",
    "\n",
    "```mermaid\n",
    "%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#E0F7FA', 'primaryTextColor': '#006064', 'primaryBorderColor': '#00BCD4', 'lineColor': '#00BCD4'}}}%%\n",
    "graph TD\n",
    "    classify2[\"classify\\n(fan-out)\"] -->|\"Send('process', {id: 1})\"| P1[\"process_order\\n(order 1)\"]\n",
    "    classify2 -->|\"Send('process', {id: 2})\"| P2[\"process_order\\n(order 2)\"]\n",
    "    classify2 -->|\"Send('process', {id: N})\"| PN[\"process_order\\n(order N)\"]\n",
    "    P1 --> agg2[\"aggregate\"]\n",
    "    P2 --> agg2\n",
    "    PN --> agg2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Send\n",
    "\n",
    "class MapReduceState(TypedDict):\n",
    "    order_ids: list[str]\n",
    "    results: Annotated[list, operator.add]\n",
    "\n",
    "class SingleOrderState(TypedDict):\n",
    "    order_id: str\n",
    "    results: Annotated[list, operator.add]\n",
    "\n",
    "def fan_out_to_orders(state: MapReduceState):\n",
    "    \"\"\"Dynamically spawn one lookup per order.\"\"\"\n",
    "    return [\n",
    "        Send(\"process_order\", {\"order_id\": oid, \"results\": []})\n",
    "        for oid in state[\"order_ids\"]  # Could be 1 or 100 orders\n",
    "    ]\n",
    "\n",
    "def process_order(state: SingleOrderState):\n",
    "    \"\"\"Process a single order (runs in parallel for each Send).\"\"\"\n",
    "    return {\"results\": [f\"Processed order {state['order_id']}\"]}\n",
    "\n",
    "def aggregate_results(state: MapReduceState):\n",
    "    \"\"\"Collect all parallel results.\"\"\"\n",
    "    return {\"results\": [f\"--- All {len(state['results'])} orders processed ---\"]}\n",
    "\n",
    "mr_builder = StateGraph(MapReduceState)\n",
    "mr_builder.add_node(\"fan_out\", lambda s: {})\n",
    "mr_builder.add_node(\"process_order\", process_order)\n",
    "mr_builder.add_node(\"aggregate\", aggregate_results)\n",
    "\n",
    "mr_builder.add_edge(START, \"fan_out\")\n",
    "mr_builder.add_conditional_edges(\"fan_out\", fan_out_to_orders, [\"process_order\"])\n",
    "mr_builder.add_edge(\"process_order\", \"aggregate\")\n",
    "mr_builder.add_edge(\"aggregate\", END)\n",
    "\n",
    "mr_graph = mr_builder.compile()\n",
    "\n",
    "result = mr_graph.invoke({\"order_ids\": [\"A1\", \"B2\", \"C3\", \"D4\"], \"results\": []})\n",
    "print(\"Map-Reduce Results:\")\n",
    "for r in result[\"results\"]:\n",
    "    print(f\"  {r}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What we have:** Fast parallel execution with reusable components.\n",
    "\n",
    "**Problem:** The agent remembers within a conversation but forgets Alice's preferences across different support tickets.\n",
    "\n",
    "---\n",
    "## Step 13: Long-Term Memory (Store)\n",
    "\n",
    "**Problem from Step 12:** Checkpointer = memory within one thread. But when Alice opens a new ticket, the agent doesn't know she prefers email contact or that she's a premium customer.\n",
    "\n",
    "**Solution:** Add a **Store** for cross-conversation memory. Checkpointer = short-term. Store = long-term.\n",
    "\n",
    "### Memory Architecture\n",
    "\n",
    "```mermaid\n",
    "%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#E8F5E9', 'primaryTextColor': '#1B5E20', 'primaryBorderColor': '#4CAF50', 'lineColor': '#4CAF50'}}}%%\n",
    "graph TD\n",
    "    subgraph \"Short-term (Checkpointer)\"\n",
    "        T1[\"Thread: ticket-100\"] --> CP1[\"Messages for this chat\"]\n",
    "        T2[\"Thread: ticket-200\"] --> CP2[\"Messages for this chat\"]\n",
    "    end\n",
    "    subgraph \"Long-term (Store)\"\n",
    "        U1[\"customers/alice/profile\"] --> P1[\"name, tier, preferences\"]\n",
    "        U2[\"customers/alice/interactions\"] --> P2[\"ticket-001, ticket-002, ...\"]\n",
    "    end\n",
    "    T1 -.->|\"reads\"| U1\n",
    "    T2 -.->|\"reads\"| U1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.1 Basic Store Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "store = InMemoryStore()\n",
    "\n",
    "# Save user preferences (persists across ALL conversations)\n",
    "namespace = (\"customers\", \"alice\")  # Like a folder path\n",
    "store.put(namespace, \"profile\", {\"name\": \"Alice\", \"tier\": \"premium\"})\n",
    "store.put(namespace, \"preferences\", {\"contact\": \"email\", \"language\": \"en\"})\n",
    "\n",
    "# Retrieve later (from ANY conversation)\n",
    "print(\"=== Alice's Long-Term Memory ===\")\n",
    "items = store.search(namespace)\n",
    "for item in items:\n",
    "    print(f\"  {item.key}: {item.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.2 Use Store in Your Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StoreState(MessagesState):\n",
    "    user_id: str\n",
    "\n",
    "def assistant_with_memory(state: StoreState, *, store):\n",
    "    \"\"\"Agent that loads user profile from long-term memory.\"\"\"\n",
    "    user_id = state.get(\"user_id\", \"unknown\")\n",
    "    namespace = (\"customers\", user_id)\n",
    "\n",
    "    # Load profile from store\n",
    "    profile = {}\n",
    "    for item in store.search(namespace):\n",
    "        profile[item.key] = item.value\n",
    "\n",
    "    system = SystemMessage(content=(\n",
    "        f\"You are a support agent. Customer profile: {profile}. \"\n",
    "        f\"Personalize your response based on their tier and preferences.\"\n",
    "    ))\n",
    "\n",
    "    response = llm_with_tools.invoke([system] + state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Build graph with store\n",
    "store_builder = StateGraph(StoreState)\n",
    "store_builder.add_node(\"assistant\", assistant_with_memory)\n",
    "store_builder.add_node(\"tools\", ToolNode(tools))\n",
    "store_builder.add_edge(START, \"assistant\")\n",
    "store_builder.add_conditional_edges(\"assistant\", tools_condition)\n",
    "store_builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "# Compile with BOTH checkpointer and store\n",
    "store_graph = store_builder.compile(\n",
    "    checkpointer=MemorySaver(),  # Short-term: this conversation\n",
    "    store=store                   # Long-term: all conversations\n",
    ")\n",
    "\n",
    "# Thread 1 — Alice's first ticket\n",
    "config1 = {\"configurable\": {\"thread_id\": \"ticket-100\", \"user_id\": \"alice\"}}\n",
    "result = store_graph.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Hi, can you help me?\")], \"user_id\": \"alice\"},\n",
    "    config1\n",
    ")\n",
    "print(\"=== Ticket 100 (Alice) ===\")\n",
    "print(result[\"messages\"][-1].content[:200])\n",
    "\n",
    "# Thread 2 — Alice's SECOND ticket (different thread, same store!)\n",
    "config2 = {\"configurable\": {\"thread_id\": \"ticket-200\", \"user_id\": \"alice\"}}\n",
    "result = store_graph.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"I have another question\")], \"user_id\": \"alice\"},\n",
    "    config2\n",
    ")\n",
    "print(\"\\n=== Ticket 200 (Alice — remembers profile!) ===\")\n",
    "print(result[\"messages\"][-1].content[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.3 Memory Patterns\n",
    "\n",
    "**Profile pattern** (single record per user) vs **Collection pattern** (many items per user):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profile pattern: One profile per user — update in place\n",
    "store.put((\"customers\", \"alice\"), \"profile\", {\n",
    "    \"name\": \"Alice\",\n",
    "    \"tier\": \"premium\",\n",
    "    \"preferred_contact\": \"email\",\n",
    "    \"notes\": \"Very technical, prefers detailed answers\"\n",
    "})\n",
    "\n",
    "# Collection pattern: Multiple memories per user — build up over time\n",
    "store.put((\"customers\", \"alice\", \"interactions\"), \"ticket-001\", {\n",
    "    \"date\": \"2024-01-15\", \"issue\": \"billing\", \"resolved\": True\n",
    "})\n",
    "store.put((\"customers\", \"alice\", \"interactions\"), \"ticket-002\", {\n",
    "    \"date\": \"2024-02-20\", \"issue\": \"shipping\", \"resolved\": True\n",
    "})\n",
    "\n",
    "# Search over past interactions\n",
    "print(\"=== Alice's Interaction History ===\")\n",
    "past = store.search((\"customers\", \"alice\", \"interactions\"))\n",
    "for item in past:\n",
    "    print(f\"  {item.key}: {item.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What we have:** Complete agent with short-term AND long-term memory.\n",
    "\n",
    "**Problem:** Only works on your laptop.\n",
    "\n",
    "---\n",
    "## Step 14: Deploy to Production\n",
    "\n",
    "**Problem from Step 13:** Agent only works locally. Need to serve it to real users.\n",
    "\n",
    "### Deployment Architecture\n",
    "\n",
    "```mermaid\n",
    "%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#E0F2F1', 'primaryTextColor': '#004D40', 'primaryBorderColor': '#009688', 'lineColor': '#009688'}}}%%\n",
    "graph LR\n",
    "    APP[\"Your App\"] -->|\"LangGraph SDK\"| SERVER[\"LangGraph Server\\n(Docker)\"]\n",
    "    SERVER --> GRAPH[\"support_agent graph\"]\n",
    "    SERVER --> DB[(\"PostgreSQL\\nCheckpoints\")]\n",
    "    SERVER --> STORE[(\"Redis/DB\\nLong-term Memory\")]\n",
    "```\n",
    "\n",
    "### Double-Texting Strategies\n",
    "\n",
    "| Strategy | What happens | When to use |\n",
    "|---|---|---|\n",
    "| `reject` | New message rejected while busy | Strict sequential processing |\n",
    "| `enqueue` | Queued, runs after current finishes | Default — process everything |\n",
    "| `interrupt` | Stops current run, starts new | Chat UX (latest message wins) |\n",
    "| `rollback` | Undoes current, restarts from before | Idempotent operations |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 14.1: Create langgraph.json (shown as reference)\n",
    "import json\n",
    "\n",
    "langgraph_config = {\n",
    "    \"graphs\": {\n",
    "        \"support_agent\": \"./agent.py:graph\"\n",
    "    },\n",
    "    \"dependencies\": [\"langchain\", \"langgraph\", \"langchain-openai\"],\n",
    "    \"env\": \".env\"\n",
    "}\n",
    "\n",
    "print(\"langgraph.json configuration:\")\n",
    "print(json.dumps(langgraph_config, indent=2))\n",
    "\n",
    "print(\"\\n--- Deployment Commands ---\")\n",
    "print(\"1. langgraph build -t support-agent    # Build Docker image\")\n",
    "print(\"2. docker compose up                    # Run on port 8123\")\n",
    "\n",
    "print(\"\\n--- SDK Usage (async) ---\")\n",
    "print(\"\"\"\n",
    "from langgraph_sdk import get_client\n",
    "\n",
    "client = get_client(url=\"http://localhost:8123\")\n",
    "thread = await client.threads.create()\n",
    "\n",
    "async for chunk in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    \"support_agent\",\n",
    "    input={\"messages\": [{\"role\": \"user\", \"content\": \"Hi\"}]},\n",
    "    config={\"configurable\": {\"user_id\": \"alice\"}}\n",
    "):\n",
    "    print(chunk.data)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Complete Code: Production-Ready Agent\n",
    "\n",
    "Everything from Steps 1-14 combined into one working agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal\n",
    "import operator\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# --- State ---\n",
    "class State(MessagesState):\n",
    "    summary: str\n",
    "    user_id: str\n",
    "    action_log: Annotated[list, operator.add]\n",
    "\n",
    "# --- Tools ---\n",
    "@tool\n",
    "def search_orders(customer_name: str) -> str:\n",
    "    \"\"\"Search for customer orders.\"\"\"\n",
    "    orders = {\"Alice\": \"Order #123: Laptop\", \"Bob\": \"Order #456: Mouse\"}\n",
    "    return orders.get(customer_name, \"No orders found\")\n",
    "\n",
    "@tool\n",
    "def check_shipping(order_id: str) -> str:\n",
    "    \"\"\"Check shipping status.\"\"\"\n",
    "    return f\"Order {order_id} arrives tomorrow\"\n",
    "\n",
    "tools = [search_orders, check_shipping]\n",
    "llm = ChatOpenAI(model=\"gpt-4o\").bind_tools(tools)\n",
    "store = InMemoryStore()\n",
    "\n",
    "# Seed some user data\n",
    "store.put((\"customers\", \"alice\"), \"profile\", {\n",
    "    \"name\": \"Alice\", \"tier\": \"premium\", \"preferred_contact\": \"email\"\n",
    "})\n",
    "\n",
    "# --- Nodes ---\n",
    "def assistant(state: State, *, store):\n",
    "    # Load long-term memory\n",
    "    profile = {}\n",
    "    if state.get(\"user_id\"):\n",
    "        for item in store.search((\"customers\", state[\"user_id\"])):\n",
    "            profile[item.key] = item.value\n",
    "\n",
    "    system = SystemMessage(content=(\n",
    "        f\"Support agent. Profile: {profile}. \"\n",
    "        f\"Summary: {state.get('summary', '')}\"\n",
    "    ))\n",
    "    return {\n",
    "        \"messages\": [llm.invoke([system] + state[\"messages\"])],\n",
    "        \"action_log\": [\"llm_call\"]\n",
    "    }\n",
    "\n",
    "def summarize(state: State):\n",
    "    msgs_text = \"\\n\".join([f\"{m.type}: {m.content}\" for m in state[\"messages\"] if m.content])\n",
    "    summary_prompt = f\"Summarize this conversation:\\n{msgs_text}\"\n",
    "    new_summary = ChatOpenAI(model=\"gpt-4o\").invoke(summary_prompt).content\n",
    "    delete = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "    return {\"summary\": new_summary, \"messages\": delete}\n",
    "\n",
    "def should_summarize(state: State) -> Literal[\"summarize\", \"__end__\"]:\n",
    "    return \"summarize\" if len(state[\"messages\"]) > 10 else \"__end__\"\n",
    "\n",
    "# --- Build Graph ---\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "builder.add_node(\"summarize\", summarize)\n",
    "\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\"assistant\", tools_condition)\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "builder.add_conditional_edges(\"assistant\", should_summarize)\n",
    "builder.add_edge(\"summarize\", END)\n",
    "\n",
    "# --- Compile with All Features ---\n",
    "graph = builder.compile(\n",
    "    checkpointer=MemorySaver(),\n",
    "    store=store,\n",
    "    interrupt_before=[\"tools\"]  # Human approval for tools\n",
    ")\n",
    "\n",
    "print(\"Production-ready agent compiled!\")\n",
    "print(\"Features: LLM, Tools, Memory, Store, HITL, Summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the complete agent\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the complete agent\n",
    "config = {\"configurable\": {\"thread_id\": \"final-demo\", \"user_id\": \"alice\"}}\n",
    "\n",
    "print(\"=== Running complete agent ===\")\n",
    "for event in graph.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"Check my orders please\")],\n",
    "     \"user_id\": \"alice\", \"action_log\": []},\n",
    "    config,\n",
    "    stream_mode=\"values\"\n",
    "):\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "# Check what's pending (HITL breakpoint)\n",
    "state = graph.get_state(config)\n",
    "if state.next:\n",
    "    print(f\"\\nPaused at: {state.next}\")\n",
    "    print(f\"Pending tool calls: {state.values['messages'][-1].tool_calls}\")\n",
    "    \n",
    "    # Approve and continue\n",
    "    print(\"\\n--- Approving tool execution ---\")\n",
    "    for event in graph.stream(None, config, stream_mode=\"values\"):\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary: What We Built\n",
    "\n",
    "| Step | Concept | Problem Solved |\n",
    "|---|---|---|\n",
    "| 1 | Simple graph (State, Nodes, Edges) | Need a structured workflow |\n",
    "| 2 | LLM + MessagesState + Reducers | Need intelligent responses |\n",
    "| 3 | Tools + ToolNode + tools_condition | LLM can't take actions |\n",
    "| 4 | ReAct loop (tools -> assistant) | LLM can't see tool results |\n",
    "| 5 | Checkpointer + thread_id | Agent forgets between calls |\n",
    "| 6 | Custom state, Pydantic, I/O schemas | Need richer state + validation |\n",
    "| 7 | Trim, filter, summarize messages | Long conversations = expensive |\n",
    "| 8 | SQLite/Postgres checkpointer | Memory lost on restart |\n",
    "| 9 | Streaming (values, messages, async) | Users wait for full response |\n",
    "| 10 | Breakpoints + edit state + dynamic interrupt | Dangerous auto tool execution |\n",
    "| 11 | get_state_history, fork, replay | Can't debug past mistakes |\n",
    "| 12 | Parallel edges, sub-graphs, Send/map-reduce | Sequential = slow |\n",
    "| 13 | InMemoryStore, namespaces, profiles | Forgets user across conversations |\n",
    "| 14 | Docker, SDK, assistants, double-texting | Only works locally |\n",
    "\n",
    "---\n",
    "\n",
    "> **You now have a complete, production-ready customer support agent** that:\n",
    "> - Remembers conversations (checkpointer)\n",
    "> - Takes actions (tools)\n",
    "> - Needs approval (interrupts)\n",
    "> - Handles long chats (summarization)\n",
    "> - Remembers users (store)\n",
    "> - Runs in parallel (Send)\n",
    "> - Is debuggable (time travel)\n",
    "> - Is deployed (LangGraph Cloud)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
